import sys
import os
import pandas as pd

from datetime import datetime, timedelta

from airflow import DAG
from airflow.sdk import chain, TaskGroup

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import app.tasks.exemple as exemple

DAG_ID = "exemple_dag"
DESCRIPTION = "Ce DAG extrait des donn√©es depuis SQL Server d'A2PO et BigQuery de GCP, puis les transmet sous forme de liste dans le XCom."
OBJECTIF = "Valider les √©tapes d'extraction des donn√©es depuis BigQuery et SQL Server."

default_args = {
    'owner': 'airflow',
    'depends_on_past': False, # Attendre l'ex√©cution pr√©c√©dente
    'retries': 0, # Nombre de tentatives avant l'√©chec d'une t√¢che
    'retry_delay': timedelta(seconds=5), # Temps entre chaque tentative
}

# D√©finition du DAG
with DAG(
    dag_id=DAG_ID, # Identifiant unique du DAG
    default_args=default_args, # Dictionnaire contenant les param√®tres par d√©faut des t√¢ches
    start_date=datetime(2025, 1, 1), # Date de d√©but du DAG
    schedule="00 1 * * 1-7",  # Fr√©quence d'ex√©cution (CRON ou timedelta)
    tags=["exemple",], # Liste de tags pour cat√©goriser le DAG dans l'UI
    catchup=False, # Ex√©cution des t√¢ches manqu√©es (True ou False)
    max_active_runs=1,  # Limite √† 1 ex√©cutions actives en m√™me temps
    dagrun_timeout=timedelta(minutes=15),
    description=DESCRIPTION,
    doc_md=f"""
        ## üîπ Description
        {DESCRIPTION}

        ## üîπ Objectif
        {OBJECTIF}
    """,
) as dag:

    task_basic_hello = exemple.Basic.hello(
        task_id="task_basic_hello",
        name="Airflow User",
    )

    task_basic_xcom = exemple.Basic.xcom(
        task_id="task_basic_xcom",
        var_test="Test de la t√¢che basic",
    )

    task_spark = exemple.Basic.spark_df(
        task_id="task_spark_df",
    )

    with TaskGroup("groupe_call_API") as groupe_call_api:

        call_api_raw = exemple.Basic.call_API(
            task_id="call_api_raw",
            http_conn_id="API_jsonplaceholder",
            endpoint="/posts/1",
            method="GET",
            data=None,
            headers={"Accept": "application/json"},
            log_response=True,
        )

        insert_warehouse = exemple.Basic.insert_warehouse(
            task_id="insert_warehouse",
            df=pd.DataFrame([
                {"id": 1, "titre": "Premier titre", "contenu": "Premier contenu"},
                {"id": 2, "titre": "Deuxi√®me titre", "contenu": "Deuxi√®me contenu"},
                {"id": 3, "titre": "Troisi√®me titre", "contenu": "Troisi√®me contenu"},
                {"id": 4, "titre": "dqdsqdsqdsq", "contenu": "dsqdq contenu"}
            ]),  # DataFrame pandas
            table_name="exemple_table",
        )

        chain(call_api_raw, insert_warehouse,)

    chain(
        [task_basic_hello, task_basic_xcom,task_spark,],
        groupe_call_api,
    )
