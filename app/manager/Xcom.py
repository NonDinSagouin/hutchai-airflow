import pandas as pd
import os
import logging
import json

from datetime import datetime

from airflow.exceptions import AirflowFailException
from airflow.sdk import Variable

import app.helper as helper

class Xcom:

    SUPPORTED_STRATEGIES = ['direct', 'file']
    SUPPORTED_FORMATS = ['json', 'parquet']

    @staticmethod
    def get(
        xcom_source : str,
        **context
    ) -> pd.DataFrame | dict | str:
        """ R√©cup√®re un DataFrame √† partir des donn√©es stock√©es dans XCom.

        Args:
            xcom_source (str): ID de la t√¢che source des donn√©es XCom
            **context: Contexte Airflow contenant TaskInstance

        Returns:
            dict | pd.DataFrame | str: Donn√©es r√©cup√©r√©es depuis XCom

        Examples:
            >>> data = Xcom.get(
            ...     xcom_source='extract_data_task',
            ...     **context
            ... )
            # Si les donn√©es sont volumineuses et stock√©es dans un fichier,
            # elles seront charg√©es automatiquement en DataFrame ou dict.
            >>> print(data.head())
                col1  col2
        """
        helper.logging_title("R√©cup√©ration des donn√©es depuis XCom", lvl=3)

        if not xcom_source:
            raise AirflowFailException("‚ùå Le param√®tre 'xcom_source' est obligatoire pour r√©cup√©rer les donn√©es depuis XCom.")

        ti = Xcom.__get_context(context)
        data = ti.xcom_pull(task_ids=xcom_source)

        if data is None:
            raise AirflowFailException(f"‚ùå Aucune donn√©e trouv√©e pour '{xcom_source}'")

        processed_data = Xcom.__process_data(data)
        Xcom.__log_result(processed_data)

        return processed_data

    @staticmethod
    def put(
        input: str | pd.DataFrame | dict,
        xcom_strategy: str = 'file',
        file_format: str = 'parquet',
        **context
    ) -> str | pd.DataFrame | dict:
        """ Pr√©pare les donn√©es pour le stockage dans XCom selon la strat√©gie choisie.

        Args:
            input (str | pd.DataFrame | dict): Donn√©es √† stocker dans XCom
            xcom_strategy (str, optionnel): Strat√©gie de stockage ('direct', 'file'). Par d√©faut √† 'file'.
            file_format (str, optionnel): Format de fichier si strat√©gie 'file' ('json' ou 'parquet'). Par d√©faut √† 'parquet'.
            **context: Contexte Airflow contenant TaskInstance

        Returns:
            str | pd.DataFrame | dict: Donn√©es √† stocker dans XCom (chemin de fichier ou donn√©es directes)

        Examples:
            >>> filepath = Xcom.put(
            ...     input=large_dataframe,
            ...     xcom_strategy='file',
            ...     file_format='parquet',
            ...     **context
            ... )
            # Le DataFrame est sauvegard√© dans un fichier Parquet et le chemin est retourn√©.
            >>> print(filepath)
            /tmp/airflow_data/task_123_20240601_153045_123456.parquet
        """

        helper.logging_title(f"Pr√©paration des donn√©es pour XCom. Format: {file_format}, Strat√©gie: {xcom_strategy}", lvl=3)

        if xcom_strategy not in Xcom.SUPPORTED_STRATEGIES:
            raise AirflowFailException("‚ùå Le param√®tre 'xcom_strategy' doit √™tre 'direct' ou 'file'.")

        if file_format not in Xcom.SUPPORTED_FORMATS:
            raise AirflowFailException("‚ùå Le param√®tre 'file_format' doit √™tre 'json' ou 'parquet'.")

        ti = Xcom.__get_context(context)

        tmp_folder = Variable.get("Folder_tmp_data", default="/tmp/airflow_data")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        output = None

        if xcom_strategy == 'file':

            task_id = ti.task_id

            # D√©terminer l'extension selon le format et le type de donn√©es
            if file_format == 'json':
                output = Xcom.__file_strategy_json(input, tmp_folder, task_id, timestamp)
            elif file_format == 'parquet':
                output = Xcom.__file_strategy_parquet(input, tmp_folder, task_id, timestamp)
            else:
                raise AirflowFailException("‚ùå Format de fichier non support√© pour la strat√©gie 'file'.")

            logging.info(f"‚úÖ Donn√©es sauvegard√©es dans: {output}")

        elif xcom_strategy == 'direct':
            logging.info("‚úÖ Donn√©es pr√™tes pour stockage direct dans XCom")
            output = input

        Xcom.__clean_tmp_files(tmp_folder=tmp_folder, older_than_minutes=60)
        helper.logging_title("‚úÖ Donn√©es pr√©par√©es pour XCom.", lvl=3, close=True)
        return output

    @classmethod
    def __get_context(cls, context: dict) -> any:
        """Validation centralis√©e du contexte Airflow"""
        if 'ti' not in context:
            raise AirflowFailException("TaskInstance manquante dans le contexte")
        
        return context.get('ti')

    @staticmethod
    def __file_strategy_json(
        input: str | pd.DataFrame | dict,
        tmp_folder: str,
        task_id: str,
        timestamp: str,
    ):
        """ Sauvegarde les donn√©es dans un fichier JSON.

        Args:
            input (str | pd.DataFrame | dict): Donn√©es √† sauvegarder
            tmp_folder (str): Dossier temporaire pour sauvegarder le fichier
            task_id (str): ID de la t√¢che Airflow
            timestamp (str): Timestamp pour nommer le fichier

        Returns:
            str: Chemin du fichier sauvegard√©
        """
        try:
            filepath = f"{tmp_folder}/{task_id}_{timestamp}.json"
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
        except Exception as e:
            raise AirflowFailException(f"‚ùå Erreur cr√©ation dossier temporaire: {str(e)}") from e

        if isinstance(input, pd.DataFrame):
            try:
                input.to_json(filepath, orient='records', index=False)
            except Exception as e:
                raise AirflowFailException(f"‚ùå Erreur sauvegarde DataFrame en JSON: {str(e)}") from e

        elif isinstance(input, dict):
            try:
                with open(filepath, 'w', encoding='utf-8') as f: json.dump(input, f, ensure_ascii=False, indent=2)
            except Exception as e:
                raise AirflowFailException(f"‚ùå Erreur sauvegarde dict en JSON: {str(e)}") from e

        else:
            try:
                with open(filepath, 'w', encoding='utf-8') as f: f.write(str(input))
            except Exception as e:
                raise AirflowFailException(f"‚ùå Erreur sauvegarde string en JSON: {str(e)}") from e

        logging.info("üíæ Fichier JSON sauvegard√© avec succ√®s")
        return filepath

    @staticmethod
    def __file_strategy_parquet(
        input: pd.DataFrame,
        tmp_folder: str,
        task_id: str,
        timestamp: str,
    ):
        """ Sauvegarde les donn√©es dans un fichier Parquet.

        Args:
            input (pd.DataFrame): DataFrame √† sauvegarder
            tmp_folder (str): Dossier temporaire pour sauvegarder le fichier
            task_id (str): ID de la t√¢che Airflow
            timestamp (str): Timestamp pour nommer le fichier

        Returns:
            str: Chemin du fichier sauvegard√©
        """

        logging.info("‚è≥ Sauvegarde du DataFrame en Parquet")
        filepath = f"{tmp_folder}/{task_id}_{timestamp}.parquet"
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        input.to_parquet(filepath, index=False)

        logging.info(f"üíæ Fichier Parquet sauvegard√© avec succ√®s")
        return filepath

    @staticmethod
    def __log_result(
        result: str | pd.DataFrame | dict
    ):
        """ Log le r√©sultat selon son type.

        Args:
            result (str | pd.DataFrame | dict): R√©sultat √† logger
        """

        if isinstance(result, pd.DataFrame):
            helper.logging_title(f"‚úÖ DataFrame avec {result.shape[0]} lignes et {result.shape[1]} colonnes.", lvl=3, close=True)

        elif isinstance(result, dict):
            helper.logging_title(f"‚úÖ Dict avec {len(result)} cl√©s.", lvl=3, close=True)

        elif isinstance(result, str):
            helper.logging_title(f"‚úÖ String avec {len(result)} caract√®res.", lvl=3, close=True)

        else:
            raise AirflowFailException(f"‚ùå Type de donn√©es non support√© pour le logging: {type(result)}")

    @staticmethod
    def __process_data(
        data: str | pd.DataFrame | dict
    ) -> pd.DataFrame | dict | str:
        """ Traite les donn√©es r√©cup√©r√©es depuis XCom.

        Args:
            data (str | pd.DataFrame | dict): Donn√©es r√©cup√©r√©es depuis XCom

        Returns:
            pd.DataFrame | dict | str: Donn√©es trait√©es
        """

        SUCCESS_LOG = "‚úÖ Donn√©es r√©cup√©r√©es et trait√©es depuis XCom."

        # Si c'est un chemin de fichier, le charger
        if isinstance(data, str) and os.path.isfile(data):
            logging.info(f"‚è≥ Chargement du fichier depuis XCom: {data}")

            # D√©terminer le format selon l'extension
            if data.endswith('.parquet'):
                try:
                    data = pd.read_parquet(data)
                except Exception as e:
                    raise AirflowFailException(f"‚ùå Erreur lecture parquet: {str(e)}")

                logging.info(SUCCESS_LOG)

            elif data.endswith('.json'):
                try:
                    with open(data, 'r') as f: data = json.load(f)
                except Exception as e:
                    raise AirflowFailException(f"‚ùå Erreur lecture JSON: {str(e)}")

                logging.info(SUCCESS_LOG)

            else:
                raise AirflowFailException("‚ùå Format de fichier non support√©")

        if data is None:
            raise AirflowFailException("‚ùå Aucune donn√©e trouv√©e dans XCom source.")
        
        logging.info(SUCCESS_LOG)
        
        return data

    @staticmethod
    def __clean_tmp_files(
        tmp_folder: str,
        older_than_minutes: int = 60
    ):
        """ Nettoie les fichiers temporaires plus anciens qu'un certain temps.

        Args:
            tmp_folder (str): Dossier temporaire √† nettoyer
            older_than_minutes (int, optionnel): Supprimer les fichiers plus anciens que ce nombre de minutes. Par d√©faut √† 60.
        """

        now = datetime.now()
        cutoff = now.timestamp() - (older_than_minutes * 60)
        deleted_count = 0

        if not os.path.exists(tmp_folder):
            logging.info(f"‚úÖ Nettoyage termin√©: le dossier temporaire '{tmp_folder}' n'existe pas.")
            return

        for filename in os.listdir(tmp_folder):
            filepath = os.path.join(tmp_folder, filename)
            if os.path.isfile(filepath):
                file_mtime = os.path.getmtime(filepath)
                if file_mtime < cutoff:
                    os.remove(filepath)
                    logging.info(f"üóëÔ∏è Fichier supprim√©: {filepath}")
                    deleted_count += 1

        if deleted_count > 0:
            logging.info(f"‚úÖ Nettoyage termin√©: {deleted_count} fichier(s) supprim√©(s).")
        else:
            logging.info("‚úÖ Nettoyage termin√©: aucun fichier √† supprimer.")