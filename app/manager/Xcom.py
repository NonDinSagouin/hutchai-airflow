import pandas as pd
import os
import logging
import json

from datetime import datetime

from airflow.exceptions import AirflowFailException
from airflow.sdk import Variable

import app.helper as helper

class Xcom:

    @staticmethod
    def get(
        xcom_source : str,
        **context
    ) -> pd.DataFrame | dict | str:
        """ R√©cup√®re un DataFrame √† partir des donn√©es stock√©es dans XCom.

        Args:
            xcom_source (str): ID de la t√¢che source des donn√©es XCom
            **context: Contexte Airflow contenant TaskInstance

        Returns:
            dict | pd.DataFrame | str: Donn√©es r√©cup√©r√©es depuis XCom

        Examples:
            >>> data = Xcom.get(
            ...     xcom_source='extract_data_task',
            ...     **context
            ... )
            # Si les donn√©es sont volumineuses et stock√©es dans un fichier,
            # elles seront charg√©es automatiquement en DataFrame ou dict.
            >>> print(data.head())
                col1  col2
        """

        if not xcom_source:
            raise AirflowFailException("‚ùå Le param√®tre 'xcom_source' est obligatoire pour r√©cup√©rer les donn√©es depuis XCom.")
        if 'ti' not in context:
            raise AirflowFailException("TaskInstance manquante dans le contexte")

        helper.logging_title("R√©cup√©ration des donn√©es depuis XCom", lvl=3)

        ti = context.get('ti')
        if not ti:
            raise AirflowFailException("‚ùå TaskInstance introuvable dans le contexte")
        data = ti.xcom_pull(task_ids=xcom_source)

        # Si c'est un chemin de fichier, le charger
        if isinstance(data, str) and os.path.isfile(data):
            logging.info(f"‚è≥ Chargement du fichier depuis XCom: {data}")

            # D√©terminer le format selon l'extension
            if data.endswith('.parquet'):
                try:
                    data = pd.read_parquet(data)
                except Exception as e:
                    raise AirflowFailException(f"‚ùå Erreur lecture parquet: {str(e)}")
                
                logging.info(f"‚úÖ Fichier parquet charg√© avec succ√®s")

            elif data.endswith('.json'):
                try:
                    with open(data, 'r') as f: data = json.load(f)
                except Exception as e:
                    raise AirflowFailException(f"‚ùå Erreur lecture JSON: {str(e)}")
                
                logging.info(f"‚úÖ Fichier JSON charg√© avec succ√®s")

            else:
                raise AirflowFailException(f"‚ùå Format de fichier non support√©")

        if isinstance(data, pd.DataFrame):
            helper.logging_title(f"‚úÖ DataFrame r√©cup√©r√© depuis XCom avec {data.shape[0]} lignes et {data.shape[1]} colonnes.", lvl=3, close=True)

        elif isinstance(data, dict):
            helper.logging_title(f"‚úÖ Dict r√©cup√©r√© depuis XCom avec {len(data)} cl√©s.", lvl=3, close=True)

        else:
            helper.logging_title(f"‚úÖ String r√©cup√©r√© depuis XCom avec {len(data)} caract√®res.", lvl=3, close=True)

        return data

    @staticmethod
    def put(
        input: str | pd.DataFrame | dict,
        xcom_strategy: str = 'auto',
        file_format: str = 'parquet',
        **context
    ) -> str | pd.DataFrame | dict:
        """ Pr√©pare les donn√©es pour le stockage dans XCom selon la strat√©gie choisie.

        Args:
            input (str | pd.DataFrame | dict): Donn√©es √† stocker dans XCom
            xcom_strategy (str, optionnel): Strat√©gie de stockage ('direct', 'file', 'auto'). Par d√©faut √† 'auto'.
            file_format (str, optionnel): Format de fichier si strat√©gie 'file' ('json' ou 'parquet'). Par d√©faut √† 'parquet'.
            **context: Contexte Airflow contenant TaskInstance

        Returns:
            str | pd.DataFrame | dict: Donn√©es √† stocker dans XCom (chemin de fichier ou donn√©es directes)

        Examples:
            >>> filepath = Xcom.put(
            ...     input=large_dataframe,
            ...     xcom_strategy='auto',
            ...     file_format='parquet',
            ...     **context
            ... )
            # Si le DataFrame est volumineux, il sera sauvegard√© dans un fichier et le chemin sera retourn√©.
            >>> print(filepath)
            /tmp/airflow_data/task_123_20240601_153045_123456.parquet
        """

        if xcom_strategy not in ['direct', 'file', 'auto']:
            raise AirflowFailException("‚ùå Le param√®tre 'xcom_strategy' doit √™tre 'direct', 'file' ou 'auto'.")
        
        if file_format not in ['json', 'parquet']:
            raise AirflowFailException("‚ùå Le param√®tre 'file_format' doit √™tre 'json' ou 'parquet'.")

        if 'ti' not in context:
            raise AirflowFailException("TaskInstance manquante dans le contexte")

        ti = context.get('ti')
        if not ti:
            raise AirflowFailException("‚ùå TaskInstance introuvable dans le contexte")

        helper.logging_title("Pr√©paration des donn√©es pour XCom", lvl=3)
        tmp_folder = Variable.get("Folder_tmp_data", default="/tmp/airflow_data")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        output = None

        # Strat√©gie adaptative selon la taille
        if xcom_strategy == 'auto':
            # Si c'est un DataFrame et > 100KB, utiliser fichier
            if isinstance(input, pd.DataFrame) and input.memory_usage(deep=True).sum() > 100 * 1024:
                xcom_strategy = 'file'
            # Si c'est un dict ou string volumineux, utiliser fichier
            elif isinstance(input, (dict, str)) and len(str(input)) > 100 * 1024:
                xcom_strategy = 'file'
            else:
                xcom_strategy = 'direct'

        logging.info(f"‚ÑπÔ∏è Strat√©gie XCom utilis√©e: {xcom_strategy}")

        if xcom_strategy == 'file':

            task_id = ti.task_id
            
            # D√©terminer l'extension selon le format et le type de donn√©es
            if file_format == 'json': output = Xcom.__file_strategy_json(input, tmp_folder, task_id, timestamp)
            else: output = Xcom.__file_strategy_parquet(input, tmp_folder, task_id, timestamp)

            logging.info(f"‚úÖ Donn√©es sauvegard√©es dans: {output}")

        elif xcom_strategy == 'direct':
            logging.info(f"‚úÖ Donn√©es pr√™tes pour stockage direct dans XCom")
            output = input

        Xcom.clean_tmp_files(tmp_folder=tmp_folder, older_than_minutes=60)
        helper.logging_title(f"‚úÖ Donn√©es pr√©par√©es pour XCom.", lvl=3, close=True)
        return output

    @staticmethod
    def __file_strategy_json(
        input: str | pd.DataFrame | dict,
        tmp_folder: str,
        task_id: str,
        timestamp: str,
    ):
        """ Sauvegarde les donn√©es dans un fichier JSON.

        Args:
            input (str | pd.DataFrame | dict): Donn√©es √† sauvegarder
            tmp_folder (str): Dossier temporaire pour sauvegarder le fichier
            task_id (str): ID de la t√¢che Airflow
            timestamp (str): Timestamp pour nommer le fichier

        Returns:
            str: Chemin du fichier sauvegard√©
        """
        filepath = f"{tmp_folder}/{task_id}_{timestamp}.json"
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        if isinstance(input, pd.DataFrame):
            logging.info("‚è≥ Sauvegarde du DataFrame en JSON")
            input.to_json(filepath, orient='records', index=False)

        elif isinstance(input, dict):
            logging.info("‚è≥ Sauvegarde du dict en JSON")
            with open(filepath, 'w', encoding='utf-8') as f: json.dump(input, f, ensure_ascii=False, indent=2)

        else:
            logging.info("‚è≥ Sauvegarde du string en JSON")
            with open(filepath, 'w', encoding='utf-8') as f: f.write(str(input))

        logging.info(f"üíæ Fichier JSON sauvegard√© avec succ√®s")
        return filepath

    @staticmethod
    def __file_strategy_parquet(
        input: pd.DataFrame,
        tmp_folder: str,
        task_id: str,
        timestamp: str,
    ):
        """ Sauvegarde les donn√©es dans un fichier Parquet.

        Args:
            input (pd.DataFrame): DataFrame √† sauvegarder
            tmp_folder (str): Dossier temporaire pour sauvegarder le fichier
            task_id (str): ID de la t√¢che Airflow
            timestamp (str): Timestamp pour nommer le fichier

        Returns:
            str: Chemin du fichier sauvegard√©
        """

        logging.info("‚è≥ Sauvegarde du DataFrame en Parquet")
        filepath = f"{tmp_folder}/{task_id}_{timestamp}.parquet"
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        input.to_parquet(filepath, index=False)

        logging.info(f"üíæ Fichier Parquet sauvegard√© avec succ√®s")
        return filepath
    
    @staticmethod
    def clean_tmp_files(
        tmp_folder: str,
        older_than_minutes: int = 60
    ):
        """ Nettoie les fichiers temporaires plus anciens qu'un certain temps.

        Args:
            tmp_folder (str): Dossier temporaire √† nettoyer
            older_than_minutes (int, optionnel): Supprimer les fichiers plus anciens que ce nombre de minutes. Par d√©faut √† 60.
        """

        now = datetime.now()
        cutoff = now.timestamp() - (older_than_minutes * 60)
        deleted_count = 0

        for filename in os.listdir(tmp_folder):
            filepath = os.path.join(tmp_folder, filename)
            if os.path.isfile(filepath):
                file_mtime = os.path.getmtime(filepath)
                if file_mtime < cutoff:
                    os.remove(filepath)
                    logging.info(f"üóëÔ∏è Fichier supprim√©: {filepath}")
                    deleted_count += 1

        if deleted_count > 0:
            logging.info(f"‚úÖ Nettoyage termin√©: {deleted_count} fichier(s) supprim√©(s).")
        else:
            logging.info("‚úÖ Nettoyage termin√©: aucun fichier √† supprimer.")